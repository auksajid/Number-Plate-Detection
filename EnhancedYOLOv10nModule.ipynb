{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BiFPN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_levels=5):\n",
        "        super(BiFPN, self).__init__()\n",
        "        self.num_levels = num_levels\n",
        "        self.w_fuse = nn.Parameter(torch.ones(self.num_levels, 4, requires_grad=True))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        BiFPN forward pass.\n",
        "\n",
        "        Args:\n",
        "            inputs: List of feature maps from different levels.\n",
        "\n",
        "        Returns:\n",
        "            List of fused feature maps.\n",
        "        \"\"\"\n",
        "        levels = len(inputs)\n",
        "        assert levels == self.num_levels\n",
        "\n",
        "        # Weighted feature fusion\n",
        "        weights = self.w_fuse / torch.sum(self.w_fuse, dim=1, keepdim=True)\n",
        "        P = [None] * levels\n",
        "\n",
        "        for i in range(levels):\n",
        "            w_top = weights[i, 0]\n",
        "            w_bot = weights[i, 1]\n",
        "            w_left = weights[i, 2]\n",
        "            w_right = weights[i, 3]\n",
        "\n",
        "            if i == 0:\n",
        "                top = inputs[i + 1]\n",
        "                left = None\n",
        "            elif i == levels - 1:\n",
        "                top = None\n",
        "                left = inputs[i - 1]\n",
        "            else:\n",
        "                top = inputs[i + 1]\n",
        "                left = inputs[i - 1]\n",
        "\n",
        "            if i == 0:\n",
        "                bot = None\n",
        "                right = inputs[i]\n",
        "            elif i == levels - 1:\n",
        "                bot = inputs[i]\n",
        "                right = None\n",
        "            else:\n",
        "                bot = inputs[i]\n",
        "                right = inputs[i]\n",
        "\n",
        "            if top is not None:\n",
        "                top = F.interpolate(top, size=inputs[i].shape[-2:], mode='nearest')\n",
        "            if left is not None:\n",
        "                left = F.interpolate(left, size=inputs[i].shape[-2:], mode='nearest')\n",
        "            if bot is not None:\n",
        "                bot = inputs[i]\n",
        "            if right is not None:\n",
        "                right = inputs[i]\n",
        "\n",
        "            P[i] = w_top * top + w_bot * bot + w_left * left + w_right * right\n",
        "\n",
        "        return P\n",
        "\n",
        "class SEAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(SEAM, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_channels // reduction, in_channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class GCNet(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GCNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 1, kernel_size=1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.size()\n",
        "        y = self.conv1(x)\n",
        "        y = self.sigmoid(y)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class YOLOv10(nn.Module):\n",
        "    def __init__(self, num_classes, anchors):\n",
        "        super(YOLOv10, self).__init__()\n",
        "        # ... (Define backbone and neck architecture) ...\n",
        "        self.bifpn = BiFPN(in_channels, out_channels)\n",
        "        self.seam = SEAM(out_channels)\n",
        "        self.gcnet = GCNet(out_channels)\n",
        "        # ... (Define head architecture) ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ... (Backbone and neck forward pass) ...\n",
        "        features = self.bifpn(features)\n",
        "        features = [self.seam(f) for f in features]\n",
        "        features = [self.gcnet(f) for f in features]\n",
        "        # ... (Head forward pass) ...\n",
        "        return outputs\n",
        "\n",
        "# Example usage\n",
        "model = YOLOv10(num_classes=80, anchors=[...])\n",
        "# ... (Load weights, define optimizer, etc.) ...\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "       # The code to follow"
      ],
      "metadata": {
        "id": "Bh_fuelUOflL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the CNN model for character recognition\n",
        "class CharacterRecognitionCNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_size=(28, 28)):\n",
        "        super(CharacterRecognitionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * (input_size[0] // 4) * (input_size[1] // 4), 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * (x.size(2) * x.size(3)))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load the trained CNN model\n",
        "model = CharacterRecognitionCNN(num_classes=36)  # 36 for characters (0-9, A-Z)\n",
        "model.load_state_dict(torch.load('character_recognition_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Preprocessing function for character images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Function to recognize a single character\n",
        "def recognize_character(character_image):\n",
        "    character_image = transform(character_image)\n",
        "    character_image = character_image.unsqueeze(0)  # Add batch dimension\n",
        "    output = model(character_image)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Example usage (assuming you have a list of detected characters)\n",
        "detected_characters = ['A', 'B', 'C', '1', '2', '3']  # Replace with actual detected characters\n",
        "\n",
        "recognized_plate = \"\"\n",
        "for character in detected_characters:\n",
        "    # Load the character image (replace with your image loading logic)\n",
        "    character_image = Image.open(f'character_{character}.jpg')\n",
        "    recognized_char = recognize_character(character_image)\n",
        "    recognized_plate += str(recognized_char)\n",
        "\n",
        "print(\"Recognized Plate:\", recognized_plate)"
      ],
      "metadata": {
        "id": "P3rYUhgJOljv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}